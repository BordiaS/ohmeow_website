{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BHSzTgLkCK_8",
        "oAkmlPKqCLAv",
        "d4tyBqxNCLAv",
        "4S1YrrNgCLAw"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIJ4cTvPCK_U",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation with blurr\n",
        "> blurr is a libray I started that integrates huggingface transformers with the world of fastai v2, giving fastai devs everything they need to train, evaluate, and deploy transformer specific models.  In this article, I provide a simple example of how to use blurr's new text generation capabilities to train, evaluate, and deploy a BART summarization model.\n",
        "\n",
        "- toc: false \n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Wayde Gilliam\n",
        "- categories: [fastai, huggingface, blurr, text generation]\n",
        "- image: images/articles/blurr-logo-small.png\n",
        "- hide: false\n",
        "- search_exclude: false\n",
        "- show_tags: true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uHRuifyCK_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f569a9d-d1b7-4f1b-d3b7-1c25f8001f87"
      },
      "source": [
        "# only run this cell if you are in collab\n",
        "!pip install ohmeow-blurr\n",
        "!pip install nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ohmeow-blurr in /usr/local/lib/python3.6/dist-packages (0.0.7)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (0.0.4)\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (0.4.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (0.0.12)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (3.0.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (4.10.1)\n",
            "Requirement already satisfied: fastai2 in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (0.0.25)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.6/dist-packages (from ohmeow-blurr) (0.1.30)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (1.18.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (0.9.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from rouge-score->ohmeow-blurr) (1.15.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (0.3.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (2.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (1.0.5)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (1.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp->ohmeow-blurr) (4.41.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->ohmeow-blurr) (2.4.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->ohmeow-blurr) (20.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->ohmeow-blurr) (5.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.13)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.22.2.post1)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.7.0+cu101)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (19.3.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (2.2.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.6.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (1.4.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai2->ohmeow-blurr) (0.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp->ohmeow-blurr) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp->ohmeow-blurr) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp->ohmeow-blurr) (1.24.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->ohmeow-blurr) (2.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->ohmeow-blurr) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->ohmeow-blurr) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->ohmeow-blurr) (2.4.7)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (49.2.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (2.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->ohmeow-blurr) (4.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->ohmeow-blurr) (0.2.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->ohmeow-blurr) (4.6.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2->ohmeow-blurr) (0.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai2->ohmeow-blurr) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2->ohmeow-blurr) (0.10.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->ohmeow-blurr) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2->ohmeow-blurr) (3.1.0)\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from nlp) (1.18.5)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlp) (1.0.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from nlp) (2.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from nlp) (0.7)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from nlp) (0.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->nlp) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq1pD_JCCK_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlp\n",
        "import pandas as pd\n",
        "from fastai2.text.all import *\n",
        "from transformers import *\n",
        "\n",
        "from blurr.data.all import *\n",
        "from blurr.modeling.all import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xELtw2ccCK_a",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri2T8Ih6CK_b",
        "colab_type": "text"
      },
      "source": [
        "We're going to use to use the new [nlp](https://github.com/huggingface/nlp) library from huggingface to grab your raw data.  This package gives you access to all kinds of NLP related datasets, explanations of each, and various task specific metrics to use in evaluating your model.  The best part being everything comes down to you in JSON!  This makes it a breeze to get up and running quickly!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJQNHvi8PsU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48bd9f96-dcfb-4231-ab11-fff71b9de656"
      },
      "source": [
        "raw_data = nlp.load_dataset('cnn_dailymail', '3.0.0')\n",
        "raw_data.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation', 'test'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYT8--DL8u-A",
        "colab_type": "text"
      },
      "source": [
        "We'll just use a subset of the training set to build both our training and validation DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNIc9YQB83LE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "d327cfeb-a24d-4449-a67a-daa45eeffb78"
      },
      "source": [
        "df = pd.DataFrame(raw_data['train'])\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
              "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
              "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
              "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kansas City, Missouri (CNN) -- The General Services Administration, already under investigation for lavish spending, allowed an employee to telecommute from Hawaii even though he is based at the GSA's Kansas City, Missouri, office, a CNN investigation has found. It cost more than $24,000 for the business development specialist to travel to and from the mainland United States over the past year. He is among several hundred GSA \"virtual\" workers who also travel to various conferences and their home offices, costing the agency millions of dollars over the past three years. Under the program, ...</td>\n",
              "      <td>The employee in agency's Kansas City office is among hundreds of \"virtual\" workers .\\nThe employee's travel to and from the mainland U.S. last year cost more than $24,000 .\\nThe telecommuting program, like all GSA practices, is under review .</td>\n",
              "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los Angeles (CNN) -- A medical doctor in Vancouver, British Columbia, said Thursday that California arson suspect Harry Burkhart suffered from severe mental illness in 2010, when she examined him as part of a team of doctors. Dr. Blaga Stancheva, a family physician and specialist in obstetrics, said both Burkhart and his mother, Dorothee, were her patients in Vancouver while both were applying for refugee status in Canada. \"I was asked to diagnose and treat Harry to support a claim explaining why he was unable to show up in a small-claims court case,\" Stancheva told CNN in a phone intervie...</td>\n",
              "      <td>NEW: A Canadian doctor says she was part of a team examining Harry Burkhart in 2010 .\\nNEW: Diagnosis: \"autism, severe anxiety, post-traumatic stress disorder and depression\"\\nBurkhart is also suspected in a German arson probe, officials say .\\nProsecutors believe the German national set a string of fires in Los Angeles .</td>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(CNN) -- Police arrested another teen Thursday, the sixth suspect jailed in connection with the gang rape of a 15-year-old girl on a northern California high school campus. Jose Carlos Montano, 18, was arrested on charges of felony rape, rape in concert with force, and penetration with a foreign object, said Richmond Police Lt. Mark Gagan. Montano was arrested Thursday evening in San Pablo, California, a small town about two miles from the city of Richmond, where the crime took place. Montano, who was held in lieu of $1.3 million bail, is accused of taking part in what police said was a 2½...</td>\n",
              "      <td>Another arrest made in gang rape outside California school .\\nInvestigators say up to 20 people took part or stood and watched the assault .\\nFour suspects appeared in court Thursday; three wore bulletproof vests .</td>\n",
              "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  ...                                        id\n",
              "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...  ...  0001d1afc246a7964130f43ae940af6bc6c57f01\n",
              "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...  ...  0002095e55fcbd3a2f366d9bf92a95433dc305ef\n",
              "2  Kansas City, Missouri (CNN) -- The General Services Administration, already under investigation for lavish spending, allowed an employee to telecommute from Hawaii even though he is based at the GSA's Kansas City, Missouri, office, a CNN investigation has found. It cost more than $24,000 for the business development specialist to travel to and from the mainland United States over the past year. He is among several hundred GSA \"virtual\" workers who also travel to various conferences and their home offices, costing the agency millions of dollars over the past three years. Under the program, ...  ...  00027e965c8264c35cc1bc55556db388da82b07f\n",
              "3  Los Angeles (CNN) -- A medical doctor in Vancouver, British Columbia, said Thursday that California arson suspect Harry Burkhart suffered from severe mental illness in 2010, when she examined him as part of a team of doctors. Dr. Blaga Stancheva, a family physician and specialist in obstetrics, said both Burkhart and his mother, Dorothee, were her patients in Vancouver while both were applying for refugee status in Canada. \"I was asked to diagnose and treat Harry to support a claim explaining why he was unable to show up in a small-claims court case,\" Stancheva told CNN in a phone intervie...  ...  0002c17436637c4fe1837c935c04de47adb18e9a\n",
              "4  (CNN) -- Police arrested another teen Thursday, the sixth suspect jailed in connection with the gang rape of a 15-year-old girl on a northern California high school campus. Jose Carlos Montano, 18, was arrested on charges of felony rape, rape in concert with force, and penetration with a foreign object, said Richmond Police Lt. Mark Gagan. Montano was arrested Thursday evening in San Pablo, California, a small town about two miles from the city of Richmond, where the crime took place. Montano, who was held in lieu of $1.3 million bail, is accused of taking part in what police said was a 2½...  ...  0003ad6ef0c37534f80b55b4235108024b407f0b\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB6-PtQy9ikf",
        "colab_type": "text"
      },
      "source": [
        "We begin by getting our hugginface objects needed for this task (e.g., the architecture, tokenizer, config, and model).  We'll use blurr's `get_hf_objects` helper method here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOPDC8zo9QhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f44a0b0c-883c-434a-e15a-7c2f5a2c5f0b"
      },
      "source": [
        "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
        "                                                                               model_cls=BartForConditionalGeneration)\n",
        "\n",
        "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['final_logits_bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bart',\n",
              " transformers.configuration_bart.BartConfig,\n",
              " transformers.tokenization_bart.BartTokenizer,\n",
              " transformers.modeling_bart.BartForConditionalGeneration)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HjtQ7Y0-DpN",
        "colab_type": "text"
      },
      "source": [
        "Next we need to build out our DataBlock.  Remember tha a DataBlock is a blueprint describing how to move your raw data into something modelable.  That blueprint is executed when we pass it a data source, which in our case, will be the DataFrame we created above. We'll use a random subset to get things moving along a bit faster for the demo as well.\n",
        "\n",
        "Notice we're specifying `max_length` to constrain our decoder inputs to 150 so that our input/predicted summaries will be padded to 150 rather than the default which is whatever you are using for your encoder inputs (e.g., the text you want summarized)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWk1XPms9QdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hf_batch_tfm = HF_TextGenerationBatchTransform(hf_arch, hf_tokenizer)\n",
        "\n",
        "blocks = ( \n",
        "    HF_TextBlock(hf_arch, hf_tokenizer), \n",
        "    HF_TextBlock(hf_arch, hf_tokenizer, hf_batch_tfm=hf_batch_tfm, max_length=150)\n",
        ")\n",
        "\n",
        "dblock = DataBlock(blocks=blocks, \n",
        "                   get_x=ColReader('article'), \n",
        "                   get_y=ColReader('highlights'), \n",
        "                   splitter=RandomSubsetSplitter(0.01, 0.005))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqtapqCn9QZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = dblock.dataloaders(df, bs=2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmu9FMXY_D4m",
        "colab_type": "text"
      },
      "source": [
        "It's always a good idea to check out a batch of data and make sure the shapes look right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMqn2v4w9P4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12258a5a-ae94-46e5-8be4-b25625bf9e1a"
      },
      "source": [
        "b = dls.one_batch()\n",
        "len(b), b[0]['input_ids'].shape, b[1].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, torch.Size([2, 512]), torch.Size([2, 150]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVjYYbQV_N2z",
        "colab_type": "text"
      },
      "source": [
        "Even better, we can take advantage of blurr's TypeDispatched version of `show_batch` to look at things a bit more intuitively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34yZKJCX_NJp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e6854cae-c672-45df-fad8-1c35eb113612"
      },
      "source": [
        "dls.show_batch(hf_tokenizer=hf_tokenizer, max_n=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'The West Ham way was beating Manchester United 4-0 on a snowy December night in 2010'... Click here to read our blogger's view on exactly what constitutes the 'West Ham way' West Ham co-chairman David Sullivan has hit back at Sir Alex Ferguson’s claims in his updated autobiography that he doesn’t know what the \"West Ham way\" is. Ferguson wrote, in updated chapters of his book, that he didn't understand the phrase, before going on to claim that the West Ham squad is 'a team of very average players' helped by Sam Allardyce. But Sullivan has hit back by saying that the Hammers – who play Manchester City on Saturday and are fourth in the Premier League – are playing attacking football that fans want to see. Aaron Cresswell leads the celebrations after Diafra Sakho scored for West Ham against Burnley. Sam Allardyce pumps his fist in celebration at the travelling West Ham fans. David Sullivan (right), pictured alongside co-owner David Gold, has hit back at Sir Alex Ferguson's claims. Writing in the West Ham programme, Sullivan said: 'I read an article this week in which Sir Alex Ferguson said he was not sure what the \"West Ham Way\" was. 'Personally I think what we are witnessing right now is exactly that. We are playing attacking football with everybody giving 100 per cent and we are getting results at the same time. 'Our strikers have scored nine times this season and given us what we sorely lacked last year - goals.' West Ham have won five of their first nine Premier League matches this season, beating Liverpool and Manchester City in the process, and are unlikely occupants of a top-four position.</td>\n",
              "      <td>Sir Alex Ferguson claims he does not understand the 'West Ham way'\\nWriting in updated chapters of his book, Ferguson also stated that West Ham have 'a team of very average players'\\nWest Ham co-chairman has hit back in his programme notes.\\nThe Hammers beat Manchester City at Upton Park on Saturday afternoon.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>By. Sarah Griffiths. Most of us take telling the time for granted. But for visually impaired people it can be a real struggle and sometimes a speaking clock just isn’t practical. However, a new tactile watch is about to hit the shops that lets people tell the time just by touching it – and it’s so stylish that many people with perfect vision are also ordering one for themselves. The Bradley Timepiece has a minimalistic titanium face with gently protruding markings, but no numbers or hands. Scroll down for video. It's about time! The Bradley Timepiece (pictured left) lets people tell the time using their sense of touch. It is named after Paralympic gold medal winner Bradley Snyder (pictured right) and features two distinctive grooves with ball bearings set inside them that denote the minutes and hours of the day. Instead of traditional watch hands, time is indicated by two ball bearings. The one towards the centre of the watch indicates the passing minutes and one marking the hours is positioned on the side. The ball bearings are connected to a watch movement beneath the casing with magnets. If the ball bearings are pressed a little too hard and are moved accidently, a user can shake their wrist and they spring back to show the correct time. Its unique feature is two ball bearings set into grooves that people can touch to tell the time. The ball in the central groove rotates to mark the minutes, while another set into the side of the timepiece travels round the face to denote the hours. Designer Hyungsoo Kim, CEO of E-onetime, which is based in Washington DC, designed the quirky timepiece while he was a student at MIT. ‘Most clocks and watches require vision and checking the time is still a big problem if you're visually impaired. We wanted to develop a timepiece where you can touch time,’ he said. ‘This is a timepiece and not a watch because you don’t have to watch this to tell the time.’ Touch the time: As well as helping visually impaired people live independently Mr Kim explained it's been a hit with people with perfect sight too. There are occasions - from lectures and job interviews to dinner with the in-laws - when looking at a watch is considered rude and telling the time by touch solves that problem, he said. Because of its striking design, the timepiece is proving a hit with everyone and Mr Kim explained that there are so many occasions – from lectures and job interviews to dinner with</td>\n",
              "      <td>The Bradley Timepiece has a minimalistic titanium face with gently protruding markings, but no numbers and no hands.\\nTwo magnetic ball bearings denote the hours and minutes of the day by moving around the tactile timepiece.\\nIt is named after Paralympic swimmer Bradley Snyder who won two gold medals and a silver in the 2012 Games.\\nThe 'watch' goes on sale in the U.S. in May and will launch in the UK and Europe afterwards at around $275 (£164)\\nBack to Mail Online home.\\nBack to the page you came from.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgH4EGhpG4tk",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys5tnLAy_Za4",
        "colab_type": "text"
      },
      "source": [
        "We'll prepare our BART model for training by wrapping it in blurr's `HF_TextGenerationModelWrapper` model object.  This class will handle ensuring all our inputs get translated into the proper arguments needed by a huggingface conditional generation model.  We'll also use a custom model splitter that will allow us to apply discriminative learning rates over the various layers in our huggingface model.\n",
        "\n",
        "Once we have everything in place, we'll freeze our model so that only the last layer group's parameters of trainable.  See [here](https://docs.fast.ai/basic_train.html#Discriminative-layer-training) for our discriminitative learning rates work in fastai.\n",
        "\n",
        "**Note:** This has been tested with BART only thus far (if you try any other conditional generation transformer models they may or may not work ... if you do, lmk either way)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkcu5FDFICSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5a4f0813-9e75-424e-f33e-75d9af05cced"
      },
      "source": [
        "text_gen_kwargs = { **hf_config.task_specific_params['summarization'], **{'max_length': 130, 'min_length': 30} }\n",
        "text_gen_kwargs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'early_stopping': True,\n",
              " 'length_penalty': 2.0,\n",
              " 'max_length': 130,\n",
              " 'min_length': 30,\n",
              " 'no_repeat_ngram_size': 3,\n",
              " 'num_beams': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GVhlRA8_NGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = HF_BaseModelWrapper(hf_model)\n",
        "model_cb = HF_TextGenModelCallback(text_gen_kwargs=text_gen_kwargs)\n",
        "\n",
        "learn = Learner(dls, \n",
        "                model,\n",
        "                opt_func=ranger,\n",
        "                loss_func=HF_MaskedLMLoss(),\n",
        "                cbs=[model_cb],\n",
        "                splitter=partial(text_gen_splitter, arch=hf_arch))#.to_fp16()\n",
        "\n",
        "learn.create_opt() \n",
        "learn.freeze()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcpCHm2_A68D",
        "colab_type": "text"
      },
      "source": [
        "Still experimenting with how to use fastai's learning rate finder for these kinds of models.  If you all have any suggestions or interesting insights to share, please let me know.  We're only going to train the frozen model for one epoch for this demo, but feel free to progressively unfreeze the model and train the other layers to see if you can best my results below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYMzd76Z_M_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9bb76027-60aa-4410-a33f-5a837d7b2103"
      },
      "source": [
        "learn.lr_find(suggestions=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(lr_min=0.0002511886414140463, lr_steep=7.585775847473997e-07)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5fXA8e/JZF9ZEgIkhAARENkJi4AKKhU3pKKWuqJUWpVabauttYu1/dVaW7XuUhfUqmipC26IVhAQZJOwyRbCEgKYnWSyTLb390cmLCEJIcydO5k5n+fJw8y9d+49l0nmzLuLMQallFKBK8juAJRSStlLE4FSSgU4TQRKKRXgNBEopVSA00SglFIBThOBUkoFuGC7AzhV8fHxJjU11e4wlFKqXVm3bl2+MSahqX2WJwIRcQBrgRxjzGWN9s0AHgFy3JueMsa80NL5UlNTWbt2rRWhKqWU3xKRvc3t80aJ4GfAViC2mf1vGWNmeyEOpZRSTbC0jUBEkoFLgRa/5SullLKP1Y3FjwP3AnUtHDNNRDaKyHwR6WFxPEoppRqxLBGIyGVArjFmXQuHfQCkGmMGA58BrzRzrlkislZE1ubl5VkQrVJKBS4rSwTjgCkisgeYB5wvIv8+9gBjTIExxuV++gIwoqkTGWPmGGPSjTHpCQlNNnorpZRqI8sSgTHmPmNMsjEmFZgOfGGMuf7YY0Sk2zFPp1DfqKyUUsqLvD6gTEQeFJEp7qd3isgWEdkA3AnM8HY8SinVHizcfIh9BeWWnFva23oE6enpRscRKKUCSUVVLUP+uIibx6Vy3yVntukcIrLOGJPe1D6dYkIppXzcN/uKqKqtY0yfzpacXxOBUkr5uJW7CnAECSNTO1lyfk0ESinl477OKmBQUhzRYdZMBqGJQCmlfFh5VQ0b9hczprc11UKgiUAppXza2j1FVNcazraofQA0ESillE/7OquA4CAhvWdHy66hiUAppXzYyqwCBifHEWVR+wBoIlBKKZ/ldNWwcf9hS6uFQBOBUkr5rLV7CqmtM5Y2FIMmAqWU8lkrswoIcQjpPa0ZP9BAE4FSSvmor3cVMLRHByJCHZZeRxOBUkr5oNLKajblHLa8Wgg0ESillE9as6eQOgNnayJQSqnA9HVWIaGOIIZbOH6ggSYCpZTyQSt3FTA0pQPhIda2D4AmAqWU8jmHK6rZcuCwV6qFQBOBUkr5nDW769sHvNFQDJoIlFLK56zeU0hocBDDUjp45XqaCJRSysdsO1TKGV2ivdI+AJoIlFLK5+zKdZLWJdpr19NEoJRSPqS8qoac4gr6JGgiUEqpgJSVVwagJQKllApUmblOQBOBUkoFrF15ToIEenaO9No1NREopZQPycx10rNzFGHB3ukxBJoIlFLKp2TmOr3aUAyaCJRSymfU1Naxp6DMq+0DoIlAKaV8xr7CcqprDX0Sorx6XU0ESinlI+zoMQSaCJRSymfsco8h6KOJQCmlAlNmrpMuMWHEhod49bqaCJRSykdk5nl3jqEGmgiUUsoHGGO8PtlcA00ESinlA3JLXThdNV4fQwCaCJRSyifY1WMINBEopZRP0ESglFIBbleek+iwYLrEhHn92poIlFLKB2TmOunTJRoR8fq1NREopZQPyMx1kmZDQzF4IRGIiENE1ovIh03sCxORt0QkU0RWiUiq1fEopZSvKamsJrfURZ8u3p1jqIE3SgQ/A7Y2s28mUGSMSQMeAx72QjxKKeVTdjU0FPtjiUBEkoFLgReaOeQK4BX34/nABWJHBZlSStnIzh5DYH2J4HHgXqCumf1JQDaAMaYGOAx0tjgmpZTyKZl5TkIcQkon7y1PeSzLEoGIXAbkGmPWeeBcs0RkrYiszcvL80B0SinlO3bllpHaOYpghz39d6y86jhgiojsAeYB54vIvxsdkwP0ABCRYCAOKGh8ImPMHGNMujEmPSEhwcKQlVLK+3bZNNlcA8sSgTHmPmNMsjEmFZgOfGGMub7RYQuAm9yPr3IfY6yKyW6rdxdSUVVrdxhKKR/iqqllrw3LUx7L6+UQEXlQRKa4n74IdBaRTODnwK+9HY+3LNx8iGueX8mDH26xOxSllA/ZV1BOnYHeXl6e8ljB3riIMWYJsMT9+PfHbK8ErvZGDHbKd7q4/91NBAnMX7efOy84g25xEXaHpZTyAbmlLgBbPxN0ZLHFjDHc984mSl01vHjTSOoM/GvpbrvDUkr5iHxnfSKIjw61LQZNBBb77zc5fPbtd9zzvX5M7N+FK4Z2543Veylwv/lKqcBW4KwCoHOU9yeba6CJwEI5xRX8ccEWRvXqxC3jewFw+4Q0XDV1vPSVlgqUUlBQ5sIRJMRFeHed4mNpIrBIXZ3hnv9soM4Y/nH1EBxB9QOm07pEc/HArry6Yi8lldU2R6mUslthWRUdI0MJCrJvUgVNBBZ5ffU+Vuwq4LeXDaBHo9GCt09Io9RVw2sr99oUnVLKV+Q7q2xtHwBNBJZZtOUQ/RJjmD6yxwn7BibFMaFfAi8u3015VY0N0SmlfEWB00WnKE0Efim7sJy0xOYXmZg9MY3Csirmrc72cmRKKV9SWFZF52j7GopBE4ElausMOcUV9OjY/ARS6amdGNWrE3OWZlFV09ycfEopf1fgrKKzlgj8z3cllVTXGnp0anmAyO0T+nCopJIFGw54KTKllC9x1dRS6qrRNgJ/lF1YDtBiiQDgvL4J9E2M5oVlWbQ0xVJltc5PpJQ/KiyrH0PQycYxBKCJwBLZRRUAJ/QWakxE+NH43mw7VMryzPwmj1m2M4+hDy7i400HPR6nUspeRwaTaYnA/2QXliMC3TuEn/TYK4Z1Jz46jH8tO3GAWWV1Lb97bzOV1XU8sGALpTruQCm/4gvTS4AmAktkF5XTNTacsGDHSY8NC3YwY2xPlu7IY/uh0uP2zVmaxZ6Ccu65qB95ThePfbbTqpCVUjbQqiE/tr+w5R5DjV03uifhIUG8sCzryLbswnKeXpzJpYO6ccfENH44KoVXVu7h2wMlFkSslLKDVg35seyicpJP0mPoWB2jQrl6RA/ezzhAbmklAA8s2IIjSPjtZWcCcO9F/YiLCOF372+mrs5v1+5RKqDkl7kIdQQRE+aVFQGapYnAw1w1tRwqqTylEgHAzPG9qK6r49UVe/ns2+/437Zc7rrw6LoFHSJDue/i/qzbW8T8dfutCF0p5WUFzio6R4c2O/DUWzQReNiB4kqMOXmPocZS46OYdGYi/161lz9+sIW+idHcPK7XccdMG57MyNSOPPTJVorcdYtKqfarsKzK9uklQBOBxx0dQ3Dqqw3dem5visur2V9UwYNXDCTEcfzbExQk/GnqQEoqa/jbp9s8Eq9Syj4FTpft00uAJgKPyy5yJ4JTLBEApPfsyPn9u3D9mBTG9O7c5DH9u8Zy09mpvLUmm8zc0iaPUUq1D/nOKuK1ROB/sgsrCHEIibEnH0PQmIjw0oyR/HnqoBaPu2NiHyJCHDz2uXYnVao906ohP5VdVE73DhFHFqKxQufoMG4Z34uPNh7U7qRKtVPlVTVUVNdq1ZA/2l9Yfso9htriR+f0JjY8mEc/22H5tZRSnucrYwhAE4HHZRdVnHTWUU+Iiwhh1rm9+Xzrd2RkF1t+PaWUZxWUNSxar4nAr5S5aigsqyLZCyUCgBnjetEpKpR/LNrulesppTynwD3PkFYN+ZnT6THUFtFhwdx2Xh+W7cxnVVaBV66plPKMI1VDWiLwL9mF7umn2zCGoK2uH9OTLjFh/GPRDowx1NTWsfVgCW+vyea1lXuorm1fq59VVtcyf91+XYNB+b0jVUM+0EZg7wQXfubIYDIvlQgAIkIdzD4/jd+/v4XLnlxOZq4T1zFLX27OKeGv0wbZPoS9tZ78YidPL97FgeIK7rzgDLvDUcoyBU4XESEOIkPt/xi2PwI/kl1UTkSIw+tFvR+M7MEnmw5RW2e4fkxPBiXFMSg5jvfW5/DkF5mkdI7kjolpXo2pLQ4eruCFZbsJcQjPfbmL6SN70KUN4zGUag8Kyqp8ojQAmgg8KruwvseQt799hwU7eHPWmBO2/3xSX/YXVfDIp9tJ7hjBFUOTWjyP01XDgowDlFfV8KNzep9SDNmF5RwormB4z44nTI3RWo8u2oExMPfmUcx4eTWPfb6Dh64c3KZzKeXr8n1kegnQROBR+4u8M4agtUSEh6cN5uDhCu75z0YSY8ObnLpi4/5i3ly9j/czDlBeVV83P6B7LGP7xLfqOlU1ddzw4ir2FJQTExbMOX3jmdivCxP6dSEhpnW/6FsPljD/m/38aHwvxqXFc8OYVOau2M2Msb3o1zWm9TetVDtRWFbVphkIrKCJwEOMMWQXljc7R5BdQoODeP76dK589it+/No6HrziLA5XVJNTVEFOcQU7v3Oy/btSIkIcXD6kG9OGJ3PXWxk8vHA7793euVWlm9dX7WVPQTm/mNSXnOIKFm/P5eNNhxCBCX0TuHlcL845I77Fc/31k23Ehocwe2J9u8CdF6Qxf102f/l4K6/cMspj/x9K+YoCZxUDusXaHQagicBjisurKauqJdmLPYZaKy4yhLk3j+L7z3zFz+ZlABDqCKJ7h3CSO0Zy/ZgUrhiWRGx4CAB3X9iXe/+7kYWbD3HxoG4tnvtwRTVP/G8n49PimX1+GiKCMYYtB0r4dMsh3ly9jxtfWk1al2hmjE3lyuFJJzSOLd+Zz5c78rj/kjOJi6yPoUNkKHdecAZ//mgrS3fkcW7fBAv+Z5SyhzGGgjKtGvI73h5DcKp6dIrks7vPY09BGUkdI4iPCiOomfmQrhyexJxlWTyyaDuTBiQS3EKd/zNLMimuqOa+S/of+cYvIgxMimNgUhyzz0/jww0HeXnFbn773mb+tnAb00Ykc93onqR1iaauzvCXj7eS3DGCG8f2PO7cN5zdk1dX7uUvH29lXFq8pfM3KeVNpa4aqmuN7YvWN9BxBB5ydAyBbyYCqF8Sc1hKR7rEhDebBACCHUHcc1E/svLK+E8Lq6HtLyrn5a/2cOWwZM7qHtfkMWHBDqaNSOaD2eOZ/5OzOa9fF/799V4ufPRLps9ZyYMffsu3B0u456J+hAU7Tnjtryb3Z9uhUuavy27bTSvlgxoGk/nCzKOgJQKPOVoi8L2qobb43oBEhqd04PHPdzB1aBIRoY4Tjvn7p9sR4JcX9T3p+USE9NROpKd2Iq90AG+vzeaNVfv4OquQQUlxXD64e5Ovu2RQV0b07MifPtxKt7gIrSJSfsGXppcALRGcVG5pJbkllSc9LruwnA6RIcS469nbOxHhV5P7812Ji7kr9pywf9P+w7yXcYCZ43sdWVe5tRJiwrhjYhpL753I6z8azZwbRzRbQhERnr52OMkdI7hl7hreXqMlA9X++dKEc6AlghN8nVXA11kFbM45zKacw3xX4iI4SHjih8O4pIWG0+yiCp+uFmqL0b07M7FfAs8uyWT6yB7ERRxNcv/38bd0jgrltgl92nx+R5AwLu3kXVS7xoXzn5+cze2vf8O9/93I/qJy7p7Ut92MllaqMV+agho0ERwnt7SS6XO+RgT6JEQztk88A5Pi+HjTQX765nqqa+uaHZS1v7Cc/t38r7/7vZP7c8kTyxj2p89O2PfgFWd5rQQUEx7CSzNGcv+7m3jii0z2F1Vw+ZDu5JZWklfqIq/URXiog59dcIZPDNlXqiUNVUPaRuCDCt3FtX9OH8aUIUfrrKeP7MEtc9dw91sZVNcarhqRfNzr6uoM+4sqmDQg0avxesOZ3WJ58aZ0Nu0/fiW0hJgwrklPbuZV1ghxBPHwtMEkd4zk0c928M76nCP7YsODcbpq2JBdzEszRmoyUD6toKyKmPDgEzpI2MWyvxYRCQeWAmHu68w3xvyh0TEzgEeAhr/op4wxL1gV08k4K2sA6BBx/LfcqLBg5t48iltfXcs98zdQU1vH9FEpR/bnlrqoqq0j2Ue7jp6u8/sncn5/30hyIsKdF5zBhWcmUllTS0J0GAkxYYSHOHg/I4e738pgxktrePnmkUSFaTJQvqmgrMpn2gfA2hKBCzjfGOMUkRBguYh8Yoz5utFxbxljZlsYR6uVuhNBdPiJ/y0RoQ5euCmdH7+2jl+/s4n56/ZTU2dw1dThdFUD3p1+OtAN6H7iiMwrhiYRJMJdb2Vw00urmXvLKKI1GSgfVOBD8wyBhb2GTD2n+2mI+8dYdT1PKHXVJ4LYJhIBQHiIgzk3juCGMT1xBAkx4cEkdQhnUFIc145OYVSvTt4MVzXh8iHdeWL6MNZnF3Pji6soray2OySlTlDYHksEIhIFVBhj6kSkL9Af+MQY0+JfmYg4gHVAGvC0MWZVE4dNE5FzgR3A3caYE/oHisgsYBZASkpK490e0/ChER3WfANoWLCDP00daFkM6vRdOrgbjiCY/cZ6rn5uJU9fN5w+CdF2h6XUEfnOKoaldLQ7jCNaWyJYCoSLSBKwCLgBmHuyFxljao0xQ4FkYJSINP4E/QBINcYMBj4DXmnmPHOMMenGmPSEBOsGFDW0EcQ0UyJQ7cfkgd14ccZIviupZMqTy/lgwwG7Q1IKqO9cUljm8qkSQWsTgRhjyoErgWeMMVcDZ7X2IsaYYmAxMLnR9gJjjMv99AVgRGvPaQWnq4YggcgmRtGq9ue8vgl8dOc59O8Wy0/fXM9v39ukS2Aq2xVXVFNnfGcMAbS+sVhE5GzgOmCme1uLn5YikgBUG2OKRSQCmAQ83OiYbsaYg+6nU4CtrY7cAqWVNUSHBetAJT/SvUME82aN4ZFPtzNnaRZrdheR0jmSorIqCsuqKCiroltcOP+cPkzXPVBeUVjmW9NLQOtLBHcB9wHvGmO2iEhv6r/ht6QbsFhENgJrgM+MMR+KyIMiMsV9zJ0iskVENgB3AjNO/RY8p7Syxm+miFBHhTiC+M0lZ/LCjenUudeNCA0O4szusUwZ0p2Csiq+/8xXfLhRq4+U9fKdvjW9BLSyRGCM+RL4EkBEgoB8Y8ydJ3nNRmBYE9t/f8zj+6hPMD6htLJa2wf82IUDErmwiUF/s89P4/bXv2H2G+vJ2FfMry/u3+LU20qdDl+bXgJa32voDeAnQC313+5jReSfxphHrAzO25yuGu13HoASY8N589Yx/Pmjb3lh+W42HzjMNek9qKkz1NYZauoMUaEOLhnUjfAQbT9Sp+dI1VCU71QNtfZTb4AxpkRErgM+AX5NfbdQv0oEpZU1PrNQhPKu0OAgHrxiIEN7dOC+dzbxdVbhCcc89vkOfnPxmUwe2FXbkVSb5TurEIGOkb5TDd3aRBDiHh08lfppIKpFxKcHh7WF01VDanyU3WEoG105PJnz+3ehuLwaR5AQ4gjCESRsPVjC/320ldte/4bRvTrxu8sGMDCp6cV4lGpJQZmLDhEhPlX92NpE8DywB9gALBWRnkBJi69oh7SNQEH9eskdIo8vGSbEJDC2T2feXJPNo4u2c/lTyxnZsxMJsWHER4XSKSqMLrFhXDKo23HTdSvVWGFZlU/1GILWNxY/ATxxzKa9IjLRmpDsU1pZQ4y2EahmBDuCuGFMT6YM6c4zSzJZt6eIrQdKyHe6KHEPRnzssx38aepALjqrq83RKl+VX+pb00tA6xuL44A/AOe6N30JPAgctigur6uqqcNVU6clAnVScREh3Hfxmcdtq66tY1POYe5/dzM/fm0dlwzqygNTzqJLTLhNUSpftLegjG/2FXHD2T3tDuU4ra2kegkoBa5x/5QAL1sVlB2c7gnntNeQaosQRxDDUzqyYPY47rmoH59vzWXSo0t5d/1+u0NTPuTvi3YQ4gjitvPavrKfFVqbCPoYY/5gjMly//wR6G1lYN7WMOGcDihTpyPEEcQdE9P45Gfn0Dcxmrvf2sCji7ZjjN/1rVCnaHPOYT7YUL/Od5dY3yoptjYRVIjI+IYnIjIOqLAmJHu0tBaBUqeqT0I0b946hmvSk3nii0x+8+5maus0GQSyhxduo2NkCLPO873v0K391PsJ8Kq7rQCgCLjJmpDs0ZAItLFYeUqwe2nN+Ogwnlmyi6KyKh6fPlQHpQWg5TvzWbYzn99eeiaxPljr0KoSgTFmgzFmCDAYGGyMGQacb2lkXtbQRqBVQ8qTRIR7J/fn95cNYOGWQ8x4eTUHD/tVYVqdRF2d4eGF20jqEOFzjcQNTunrrzHm2LEDPwce92w49jmyKI1WDSkL3DK+F52iQvnlfzZw9kNf0CUmjEFJcQxKjmNEz46MT4vX0cp+6qNNB9mUc5h/XD3EZxarb+x0PvX86rf2aIlAE4GyxtRhSQzoHsvynflsyjnMppzDfLE9F2Ng2vBk/nLlQJ/9oFBtU11bx98Xbad/1ximDkuyO5xmnc6nnl+1fB1pLNY2AmWhvokx9E08uu5BmauGOUuz+Of/dpJdWM5zN4ygk48NNlJt969lWewtKOflGSNxBPnud+cW2whEpFRESpr4KQW6eylGryitrCHUEaQNecqrosKCuXtSX5744TAy9hcz9emvyMwttTss5QGrdxfyj0U7uHRQNyb0s26JXU9oMREYY2KMMbFN/MQYY/zqq7PTVa3tA8o2U4Z0Z96sMZRX1fL9Z1bwxbbv7A5JnYZ8p4ufvvkNPTpG8Ndpg3y+/cd3pr+zWf3qZJoIlH2Gp3Tk/dnjSOoQwS1z1zLr1bXsLSizOyx1imrrDHfNy6CovJpnrhvRLnoiaiJwc1bqojTKfkkdInjvjnHcO7kfyzPzmfToUv76ybYjnRmU73vyi50sz8znwSlnMaB7rN3htIomAjctEShfER7i4PYJaSz55QSmDO3Oc1/uYsIjS7S6qB1YvjOff/5vJ1cOT+IHI3vYHU6raSJwK3XVEB3m+0U4FTi6xIbz96uH8P4d4+gSE8bMV9by9OJMnbfIR+WVurjrrfWkJUTz56kDfb5d4FiaCNxKK6uJ1RKB8kFDenTgv7eNZcqQ7jzy6XbueOMbyrSqyKcYY7h3/gZKK2t4+rrhRIa2r88STQRuTleN9hpSPisi1MHjPxjK/ZecycLNh5j27Ar2FZTbHZZy+/eqfSzensd9F/c/bpxIe6GJgPpsrm0EyteJCLee25u5N4/i4OFKLntyGe9n5GhVkc125Tn5v4++5dy+Cdx4dqrd4bSJJgKgsrqO2jqjbQSqXTi3bwILZo+jT5dofjYvg9lvrKewrMrusAJSdW0dd83LICLEwSNXDSbIh0cPt0QTAccuSqMlAtU+9OwcxX9+fDb3XNSPRd8e4nuPLeV/W7VXkbf98/OdbMo5zENXDiLRxxabORWaCKjvMQSaCFT7EuxeDe39O8YTHx3KzFfW8sT/dtodVsBYlVXAM0syuSY9mckDu9kdzmnRRIBOOKfatwHdY3l/9jimDu3OY5/vYOWuArtD8nsLNx/i5rlrSOkUye8vP8vucE6bJgLqRxWDLkqj2q+wYAd/uXIQvTpH8fO3MzhcXm13SH7JGMNTX+zkJ/9eR9/EGN7+8dl+8QVSEwHHLErjB2+oClyRocH8c/ow8kpd/ObdTdqbyMMqq2u5c14Gf1+0g+8PS2LerDE+twh9W2kiQNsIlP8YlBzHL77Xj482HeS/3+TYHY7fKK2s5prnV/LhxgP8anJ/Hr1miF9NWa+JgGMWrtdEoPzArHN7M6Z3J/7w/madvdRD3l2fw8b9h3nm2uHcNqFPu5o+ojU0EXC0jUCrhpQ/cAQJj14zFEeQ8LN5GVRU1dodUru3IOMA/RJjuHhQ++4d1BxNBNQvShMR4iDYof8dyj907xDBQ1cOJiO7mAsf/ZIPNx7QNoM2yimuYO3eIqYM9atFGY+jn3zoFNTKP106uBtvzRpDXEQIs99Yzw+e/5rNOYftDqvd+WDDAQAuH6yJwK+V6oRzyk+N7t2ZD346nr98fxCZeU4uf2o5DyzYQnVtnd2htRsLMg4wtEcHUjpH2h2KZTQR0FAi0DEEyj85goRrR6ew+JcTuHFMT+au2MMtc9dQUqljDU4mM9fJtwdLmDLEf0sDoIkAAGdlNTHaUKz8XFxECH+8YiB/u2owK3cVcPWzK8kprrA7LJ+2YMMBggQuG+yfjcQNNBGgbQQqsFyT3oNXbhnFgeIKvv/0V9pu0AxjDB9sOMCY3p39ZuBYczQR4F6URksEKoCMS4tn/m1jCXEEcc3zK1myPdfukHzO5pwSdueXcbmfVwuBhYlARMJFZLWIbBCRLSLyxyaOCRORt0QkU0RWiUiqVfG0RNsIVCDq1zWGd28fS2rnKG59dS0LNx+yOySfsmBDDiEO4eKBXe0OxXJWlghcwPnGmCHAUGCyiIxpdMxMoMgYkwY8BjxsYTxNqqszukylClhdYsN5c9YYBibFcccb3/B+hk5LAfWfCx9uPMi5ZyTQITLU7nAsZ1kiMPWc7qch7p/GI1quAF5xP54PXCBeHrvtrKofVawL16tAFRcRwmszRzMytSN3vZXBvNX77A7Jdmv2FHLwcKVfDyI7lqVtBCLiEJEMIBf4zBizqtEhSUA2gDGmBjgMdG7iPLNEZK2IrM3Ly/NojDq9hFL1v/9zbx7FeX0T+PU7m3hp+W67Q7LVgg0HCA8J4sIzE+0OxSssTQTGmFpjzFAgGRglIgPbeJ45xph0Y0x6QkKCR2M8siiNlghUgAsPcfD8DSOYfFZXHvzwWx7/fEdATkuRU1zBe+tz+N6ArkQFyBdEr/QaMsYUA4uByY125QA9AEQkGIgDvLq8ktPVsF6xNhYrFRbs4Klrh3HViGQe/3wnDyzYQl1d4CQDYwy/eWcTBrjnon52h+M1VvYaShCRDu7HEcAkYFujwxYAN7kfXwV8Ybz8FaREq4aUOk6wI4i/TRvMj8b34pWVe7n77YyAmZLinW9y+HJHHvde1I8enfx3SonGrPz06wa8IiIO6hPO28aYD0XkQWCtMWYB8CLwmohkAoXAdAvjaVJDG4E2Fit1VFCQcP+lZ9IxKpRHPt1OSUU1z1w3gohQ/1mMpbHc0koe/PBb0nt25MazU+0Ox6ss+/QzxmwEhjWx/ffHPK4ErrYqhtbQNgKlmiYi3O8ywxoAAA6aSURBVDExjY6Rodz/3iYueWIZt0/ow9RhSYT44ZTtf3h/CxXVtTx81WCCgvxr4ZmT8b938xRpG4FSLbt2dApzbx5FRIiDe+ZvZOLfl/D6qr24avxnwZtPNh3kk82HuOvCM+iTEG13OF6niaCyBhGI9KP1R5XytPP6JvDRneN5aUY68dFh3P/uZs772xJeWJaF073md3tVVFbF797fwqCkOGad09vucGwR8ImgpLJ+nqFAKwoqdapEhPP7J/Lu7WP598zRpMZH8uePtnL2Q//j4YXbyC2ptDvENnn0sx0Ul1fx8LTBAbtKYcBXjDtdNToFtVKnQEQYf0Y848+IZ0N2MXOWZvH8l7t4cdlurh2dwm8uOZPQ4Pbxgbo7v4w3V+/jh6NSGNA91u5wbBPwn4ClldXaPqBUGw3p0YGnrxvOnvwynl+6i7kr9rArz8mz149oF12y/75oO6HBQfz0gjS7Q7FV+0jbFtIJ55Q6fanxUTx05WD+dtVgVuwq4AfPryS31LerijbuL+ajjQf50fhedInx7/UGTibgE4EuSqOU51yT3oMXbkwnK6+Mac+uICvPefIX2eThhdvoFBXKrecGZgPxsQI+ETgrdVEapTxpYv8uvDlrDGWuWqY9u4LF23LbNGdRdW0du/PL+HJHHq+t3MPrq/Z6rIfSsp15fJVZwOyJaVo1jLYRUKKL0ijlcUN7dOCd28Zyy9w13Dx3DaN7deLeyf0Z0bNji68zxvDRpoM8/vlOsvKcNJ7m6JFPt3Pz2F7MGJtKXGTb/m7r6gx//WQbyR0juG5MSpvO4W8CPhE4XdVaNaSUBVLjo1h417nMW7OPJ/63k2nPrmDSgER+8b2+9O96Yg+dzNxSfv/+FlbsKmBAt1jumJhGSqdIenaOomfnSHKKK3hmcSaPfb6Dfy3L4oaze3LzuNRTrt//cNNBthwo4bEfDCEsWMcPAUh7m2Y2PT3drF271iPnqq6t44z7P+EXk/ry0wvO8Mg5lVInKnPV8PJXu3n+yyxKXTUkxoYxrEdHhqV0YEiPDizelsuLy3cTGergnov6ce3onjiaGdvz7YESnl6SycebDuIQYdKARK4dncK4PvEnHQ+UlefkppdXExUazMd3nhNQ44dEZJ0xJr2pfQH9Vdip8wwp5RVRYcHMPv8Mrhvdk/czclifXcz6fcUs3HJ0neRr0pP51eT+dI4Oa/FcA7rH8vS1w9mdX8Ybq/Yyf91+Ptl8iJ6dI5k+MoVLB3UjpfPxM4eWVlbz5BeZvPzVbsKCHTxy1ZCASgInE9Algn0F5Zz7yGIeuWowV6f38Mg5lVKtl+90sSG7mMTYcAYmxbXpHJXVtSzcfIg3Vu1j9Z5CAPolxjBpQCKTBiSy/btS/rZwO/lOF1ePSOaeyf0CsruolgiaUaoTzillq/joMC44zeUgw0McTB2WxNRhSewrKOezrd+xaMshnlmSyVOLMwEYltKBF29KZ0iPDp4I2+8EdiJwVw1pY7FS/iGlcyQzx/di5vheFJVVsXh7LpGhDr43oKtWBbUgoD8BnZoIlPJbHaNCuXJ4st1htAsBPaCsoWpIB5QppQJZQCeCoyUCbSNQSgWugE4EJVo1pJRSgZ0InK4aQhxCWDuZO10ppawQ0J+ADRPOiWhvAqVU4AroRKCL0iilVIAnAqdLp6BWSqmATgQHiivpEtvyvCZKKeXvAjYR1NUZdueX0Ts+2u5QlFLKVgGbCA6VVFJRXUvvhCi7Q1FKKVsFbCLY5V5LVROBUirQBWwiyMorA6BPglYNKaUCWwAnAifRYcF0idHGYqVUYAvcRJBfRu+EKB1MppQKeIGbCPLK6B2v7QNKKRWQiaC8qoac4gp6a/uAUkoFZiLYnV/fUKw9hpRSKkATgfYYUkqpowI2EYhAL20jUEqpwEwEu/KcdI+LIDzEYXcoSillu4BMBFn5Tm0fUEopt4BLBMYYdueVafuAUkq5BVwi+K7ERVlVLX20RKCUUoCFiUBEeojIYhH5VkS2iMjPmjhmgogcFpEM98/vrYqnQdaRyea0RKCUUgBWLs9VA/zCGPONiMQA60TkM2PMt42OW2aMuczCOI6js44qpdTxLCsRGGMOGmO+cT8uBbYCSVZdr7V25ZURGeqga2y43aEopZRP8EobgYikAsOAVU3sPltENojIJyJyVjOvnyUia0VkbV5e3mnFkpVfRq94nWxOKaUaWJ4IRCQa+C9wlzGmpNHub4CexpghwJPAe02dwxgzxxiTboxJT0hIOK14svKc2mNIKaWOYWkiEJEQ6pPA68aYdxrvN8aUGGOc7scfAyEiEm9VPJXVte7J5rR9QCmlGljZa0iAF4GtxphHmzmmq/s4RGSUO54Cq2LanV+GMdpjSCmljmVlr6FxwA3AJhHJcG/7DZACYIx5DrgKuE1EaoAKYLoxxlgVUMNkc7oOgVJKHWVZIjDGLAdabJE1xjwFPGVVDI1laddRpZQ6QUCNLM7KL6N7XDiRoVYWhJRSqn0JqESwK8+p7QNKKdVIwCQCY0z9OsVaLaSUUscJmESQV+rC6arRhmKllGokYBLBroYeQ1o1pJRSxwmYRFDmqqFbXLhWDSmlVCMB033mwgGJXDgg0e4wlFLK5wRMiUAppVTTNBEopVSA00SglFIBThOBUkoFOE0ESikV4DQRKKVUgNNEoJRSAU4TgVJKBTixcB0YS4hIHrDX/TQOONzE4+b2xQP5Hgij8bXaclxz+1q6j8bPm3vsifts7T2e7Nim9rVmm6/dpyfey8bb9HdWf2fboq3vZU9jTNOLvhtj2u0PMKepx83tA9Z6+rptPa65fS3dR0v33Ojxad9na++xLffZmm2+dp+eeC9bupfm9unvrP7OWvFeNv5p71VDHzTz+GT7PHndth7X3L6W7qPxc1+4x5Md29S+1mzztfv0xHvZeJv+znqW/s627bj2VzV0OkRkrTEm3e44rKb36T8C4R5B79Nu7b1EcKrm2B2Al+h9+o9AuEfQ+7RVQJUIlFJKnSjQSgRKKaUa0USglFIBThOBUkoFOE0EbiJyjog8JyIviMgKu+OxiogEicj/iciTInKT3fFYQUQmiMgy9/s5we54rCQiUSKyVkQuszsWq4jIme73cr6I3GZ3PFYQkaki8i8ReUtEvuft6/tFIhCRl0QkV0Q2N9o+WUS2i0imiPy6pXMYY5YZY34CfAi8YmW8beWJ+wSuAJKBamC/VbG2lYfu0QBOIBwfvEfw2H0C/Ap425ooT5+H/ja3uv82rwHGWRlvW3joHt8zxtwK/AT4gZXxNsUveg2JyLnU/+G/aowZ6N7mAHYAk6j/MFgD/BBwAA81OsUtxphc9+veBmYaY0q9FH6reeI+3T9FxpjnRWS+MeYqb8XfGh66x3xjTJ2IJAKPGmOu81b8reWh+xwCdKY+4eUbYz70TvSt56m/TRGZAtwGvGaMecNb8beGhz9//gG8boz5xkvhA36yeL0xZqmIpDbaPArINMZkAYjIPOAKY8xDQJPFaBFJAQ77YhIAz9yniOwHqtxPa62Ltm089V66FQFhVsR5ujz0Xk4AooABQIWIfGyMqbMy7lPlqffTGLMAWCAiHwE+lQg89F4K8FfgE28nAfCTRNCMJCD7mOf7gdEnec1M4GXLIrLGqd7nO8CTInIOsNTKwDzolO5RRK4ELgI6AE9ZG5pHndJ9GmPuBxCRGbhLQZZG5zmn+n5OAK6kPql/bGlknnOqf5c/BS4E4kQkzRjznJXBNebPieCUGWP+YHcMVjPGlFOf8PyWMeYd6hNeQDDGzLU7BisZY5YAS2wOw1LGmCeAJ+y6vl80FjcjB+hxzPNk9zZ/Ewj3GQj3CHqf/qRd3aM/J4I1wBki0ktEQoHpwAKbY7JCINxnINwj6H36k3Z1j36RCETkTWAl0E9E9ovITGNMDTAb+BTYCrxtjNliZ5ynKxDuMxDuEfQ+8aP79Id79Ivuo0oppdrOL0oESiml2k4TgVJKBThNBEopFeA0ESilVIDTRKCUUgFOE4FSSgU4TQTKL4iI08vX88iaFVK/dsJhEckQkW0i8vdWvGaqiAzwxPWVAk0ESjVJRFqch8sYM9aDl1tmjBkKDAMuE5GTzbk/lfoZR5XyCE0Eym+JSB8RWSgi66R+xbL+7u2Xi8gqEVkvIp+71y1ARB4QkddE5CvgNffzl0RkiYhkicidx5zb6f53gnv/fPc3+tfdUwojIpe4t60TkSdEpMX1AowxFUAG9TNXIiK3isgaEdkgIv8VkUgRGQtMAR5xlyL6NHefSrWWJgLlz+YAPzXGjAB+CTzj3r4cGGOMGQbMA+495jUDgAuNMT90P+9P/ZTWo4A/iEhIE9cZBtzlfm1vYJyIhAPPAxe7r59wsmBFpCNwBkenB3/HGDPSGDOE+mkKZhpjVlA/Z809xpihxphdLdynUq2i01ArvyQi0cBY4D/uL+hwdJGaZOAtEekGhAK7j3npAvc38wYfGWNcgEtEcoFETlz+crUxZr/7uhlAKvUrVmUZYxrO/SYwq5lwzxGRDdQngceNMYfc2weKyJ+pX1chmvp5a07lPpVqFU0Eyl8FAcXuuvfGnqR+CcsF7kVPHjhmX1mjY13HPK6l6b+Z1hzTkmXGmMtEpBfwtYi8bYzJAOYCU40xG9yLz0xo4rUt3adSraJVQ8ovGWNKgN0icjXULwUoIkPcu+M4Ojf8TRaFsB3ofcwShiddkNxdevgr9QvSA8QAB93VUceuu1zq3ney+1SqVTQRKH8R6Z4CuOHn59R/eM50V7tsAa5wH/sA9VUp64B8K4JxVy/dDix0X6cUONyKlz4HnOtOIL8DVgFfAduOOWYecI+7sbsPzd+nUq2i01ArZRERiTbGON29iJ4GdhpjHrM7LqUa0xKBUta51d14vIX66qjnbY5HqSZpiUAppQKclgiUUirAaSJQSqkAp4lAKaUCnCYCpZQKcJoIlFIqwGkiUEqpAPf/3eKZZA+A/eYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_xhrbcgAtS0",
        "colab_type": "text"
      },
      "source": [
        "It's also not a bad idea to run a batch through your model and make sure the shape of what goes in, and comes out, looks right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYTk9W-s_NC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa25da0a-77b0-4da8-91d5-ae6eb5c2aca8"
      },
      "source": [
        "b = dls.one_batch()\n",
        "preds = learn.model(b[0])\n",
        "len(preds),preds[0], preds[1].shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,\n",
              " tensor(2.6405, device='cuda:0', grad_fn=<NllLossBackward>),\n",
              " torch.Size([2, 149, 50264]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nLRDgWB_M6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "8dbe4476-9da7-4651-de60-a85f25280a53"
      },
      "source": [
        "learn.fit_one_cycle(1, lr_max=3e-5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.310324</td>\n",
              "      <td>1.394706</td>\n",
              "      <td>0.418580</td>\n",
              "      <td>0.200035</td>\n",
              "      <td>0.293107</td>\n",
              "      <td>45:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyY99QfQBRD1",
        "colab_type": "text"
      },
      "source": [
        "And now we can look at the \"greedy decoded\" predictions ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjkuilnLBWB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "c536ede1-7cc1-4217-9461-b2c7e22fdb8d"
      },
      "source": [
        "learn.show_results(learner=learn, max_n=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-83740b3d5086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mshow_results\u001b[0;34m(self, ds_idx, dl, max_n, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_decoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/data/core.py\u001b[0m in \u001b[0;36mshow_results\u001b[0;34m(self, b, out, max_n, ctxs, show, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/blurr/modeling/text_generation.py\u001b[0m in \u001b[0;36mshow_results\u001b[0;34m(x, y, samples, outs, learner, ctxs, max_n, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtypedispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mHF_TextGenerationInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mgen_text_txts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_txt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_txt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_text_txts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcmpeMrOBaox",
        "colab_type": "text"
      },
      "source": [
        "Even better though, blurr augments the fastai Learner with a `generate_text` method that allows you to use huggingface's `PreTrainedModel.generate` method to create something more human-like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwUkWbYJ_M3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_article = \"\"\"\n",
        "The past 12 months have been the worst for aviation fatalities so far this decade - with the total of number of people killed if airline crashes reaching 1,050 even before the Air Asia plane vanished. Two incidents involving Malaysia Airlines planes - one over eastern Ukraine and the other in the Indian Ocean - led to the deaths of 537 people, while an Air Algerie crash in Mali killed 116 and TransAsia Airways crash in Taiwan killed a further 49 people. The remaining 456 fatalities were largely in incidents involving small commercial planes or private aircraft operating on behalf of companies, governments or organisations. Despite 2014 having the highest number of fatalities so far this decade, the total number of crashes was in fact the lowest since the first commercial jet airliner took off in 1949 - totalling just 111 across the whole world over the past 12 months. The all-time deadliest year for aviation was 1972 when a staggering 2,429 people were killed in a total of 55 plane crashes - including the crash of Aeroflot Flight 217, which killed 174 people in Russia, and Convair 990 Coronado, which claimed 155 lives in Spain. However this year's total death count of 1,212, including those presumed dead on board the missing Air Asia flight, marks a significant rise on the very low 265 fatalities in 2013 - which led to it being named the safest year in aviation since the end of the Second World War. Scroll down for videos. Deadly: The past 12 months have been the worst for aviation fatalities so far this decade - with the total of number of people killed if airline crashes reaching 1,158 even before the Air Asia plane (pictured) vanished. Fatal: Two incidents involving Malaysia Airlines planes - one over eastern Ukraine (pictured) and the other in the Indian Ocean - led to the deaths of 537 people. Surprising: Despite 2014 having the highest number of fatalities so far this decade, the total number of crashes was in fact the lowest since the first commercial jet airliner took off in 1949. 2014 has been a horrific year for Malaysia-based airlines, with 537 people dying on Malaysia Airlines planes, and a further 162 people missing and feared dead in this week's Air Asia incident. In total more than half the people killed in aviation incidents this year had been flying on board Malaysia-registered planes. In January a total of 12 people lost their lives in five separate incidents, while the same number of crashes in February killed 107. \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzxPEvEX_MzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = learn.generate_text(test_article, early_stopping=True, num_beams=4, num_return_sequences=3)\n",
        "\n",
        "for idx, o in enumerate(outputs):\n",
        "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW4Lzf_6B0el",
        "colab_type": "text"
      },
      "source": [
        "What about inference?  Easy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0NMTcsA_Mr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.export(fname='ft_cnndm_export.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i131wpNq_MmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inf_learn = load_learner(fname='ft_cnndm_export.pkl')\n",
        "inf_learn.generate_text(test_article)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I62bUlZ-CK_b",
        "colab_type": "text"
      },
      "source": [
        "## That's it\n",
        "\n",
        "[blurr](https://ohmeow.github.io/blurr/) supports a number of huggingface transformer model tasks in addition to text generation (e.g., sequence classification , token classification, and question/answering). The docs include examples for each of these tasks if you're curious to learn more.\n",
        "\n",
        "For more information about ohmeow or to get in contact with me, head over to [ohmeow.com](ohmeow.com) for all the details.\n",
        "\n",
        "Thanks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmFkD6C4LTX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}